# Ethics

## Code of Ethics

GENERAL ETHICAL PRINCIPLES:

- Contribute to society and to human well-being, acknowledging that all people are stakeholders in computing.
- Avoid harm.
- Be honest and trustworthy.
- Be fair and take action not to discriminate.
- Respect the work required to produce new ideas, inventions, creative works, and computing artifacts.
- Respect privacy.
- Honor confidentiality.

PROFESSIONAL RESPONSIBILITIES:

- Strive to achieve high quality in both the processes and products of professional work.
- Maintain high standards of professional competence, conduct, and ethical practice.
- Know and respect existing rules pertaining to professional work.
- Accept and provide appropriate professional review.
- Give comprehensive and thorough evaluations of computer systems and their impacts, including analysis of possible risks.
- Perform work only in areas of competence.
- Foster public awareness and understanding of computing, related technologies, and their consequences.
- Access computing and communication resources only when authorized or when compelled by the public good.
- Design and implement systems that are robustly and usably secure.

## Ethics in the workplace

basically Dont ever code somthing unethical that would cause problems for others it is confirmed that some of medical websites led lots of young people to their death by recommending drugs in order to push it to stores

you can take google emplyees as an example The employee backlash over Google’s censored search engine for China
Internal documents leaked to journalists described how the app-based search platform could block internet users in China from seeing web pages that discuss human rights, peaceful protests, democracy and other topics blacklisted by China’s authoritarian government.

The internal backlash among employees represents mounting concerns about whether Google has “lost its moral compass” in the corporate pursuit to enrich shareholders. But it also suggests that the people who make Google’s technology have more power in shaping corporate decisions than even shareholders have. In April, thousands of Google employees protested the company’s military contract with the Pentagon — known as project Maven — which developed technology to analyze drone video footage that could potentially identify human targets.

Following employee protests at Google and Microsoft over government contracts, workers at Amazon are circulating an internal letter to CEO Jeff Bezos, asking him to stop selling the company’s Rekognition facial recognition software to law enforcement and to boot the data-mining firm Palantir from its cloud services.

Amazon employees objected to the Trump administration’s “zero-tolerance” policy at the U.S. border, which has resulted in thousands of children being separated from their parents.

“Along with much of the world we watched in horror recently as U.S. authorities tore children away from their parents,” the letter, distributed on a mailing list called ‘we-won’t-build-it,’ states. “In the face of this immoral U.S. policy, and the U.S.’s increasingly inhumane treatment of refugees and immigrants beyond this specific policy, we are deeply concerned that Amazon is implicated, providing infrastructure and services that enable ICE and DHS.”

## Ethics in Technology

Imagine if

```
It’s a bright, sunny day and you’re alone in your spanking new self-driving vehicle, sprinting along the two-lane Tunnel of Trees on M-119 high above Lake Michigan north of Harbor Springs. You’re sitting back, enjoying the view. You’re looking out through the trees, trying to get a glimpse of the crystal blue water below you, moving along at the 45-m.p.h. speed limit.

As you approach a rise in the road, heading south, a school bus appears, driving north, one driven by a human, and it veers sharply toward you. There is no time to stop safely, and no time for you to take control of the car.
```

Does the car:

- A. Swerve sharply into the trees, possibly killing you but possibly saving the bus and its occupants?

- B. Perform a sharp evasive maneuver around the bus and into the oncoming lane, possibly saving you, but sending the bus and its driver swerving into the trees, killing her and some of the children on board?

- C. Hit the bus, possibly killing you as well as the driver and kids on the bus?

> **Who dies when the car is forced into a no-win situation?**

“There will be crashes,” said Van Lindberg, an attorney in the Dykema law firm's San Antonio office who specializes in autonomous vehicle issues. “Unusual things will happen. Trees will fall. Animals, kids will dart out.” Even as self-driving cars save thousands of lives, he said, “anyone who gets the short end of that stick is going to be pretty unhappy about it.”

Last month, Sebastian Thrun, who founded Google’s self-driving car initiative, told Bloomberg that the cars will be designed to avoid accidents, but that “If it happens where there is a situation where a car couldn’t escape, **it’ll go for the smaller thing**.”

**But what if the smaller thing is a child?**

How that question gets answered may be important to the development and acceptance of self-driving cars.

Azim Shariff, an assistant professor of psychology and social behavior at the University of California, Irvine, co-authored a study last year that found that while respondents generally agreed that a car should, in the case of an inevitable crash, kill the fewest number of people possible regardless of whether they were passengers or people outside of the car

they were less likely to buy any car **“in which they and their family member would be sacrificed for the greater good.”**

In My opinion: focus on the safty of the cars instead of self-driving and stop it
or even create a huge network to connect cars togather so they reduce accidents numbers

**Experts say that self-driving cars will be particularly susceptible to hackers. What makes them so vulnerable?**


The answer to this question depends on what kind of a self-driving car we are talking about and how connected the car is to the outside world. If the car does any significant computations by connecting to the outside world via the cloud, needs some sort of internet-connectivity for its functionality, or completely relies on outside sensors for making all decisions, then yes, it might be susceptible to hackers.

> **Great, I wAnt tO bUy A sElf-DrIvINg cAR nOw**

### **Will Democracy Survive Big Data and Artificial Intelligence?**

The digital revolution is in full swing. How will it change our world? The amount of data we produce doubles every year. In other words: in 2016 we produced as much data as in the entire history of humankind through 2015. Every minute we produce hundreds of thousands of Google searches and Facebook posts. These contain information that reveals how we think and feel. Soon, the things around us, possibly even our clothing, also will be connected with the Internet. It is estimated that in 10 years’ time there will be 150 billion networked measuring sensors, 20 times more than people on Earth. Then, the amount of data will double every 12 hours. Many companies are already trying to turn this Big Data into Big Money.

One thing is clear: the way in which we organize the economy and society will change fundamentally. We are experiencing the largest transformation since the end of the Second World War; after the automation of production and the creation of self-driving cars the automation of society is next. With this, society is at a crossroads, which promises great opportunities, but also considerable risks. If we take the wrong decisions it could threaten our greatest historical achievements.

These technologies are also becoming increasingly popular in the world of politics. Under the label of “nudging,” and on massive scale, governments are trying to steer citizens towards healthier or more environmentally friendly behaviour by means of a "nudge"—a modern form of paternalism. The new, caring government is not only interested in what we do, but also wants to make sure that we do the things that it considers to be right.
